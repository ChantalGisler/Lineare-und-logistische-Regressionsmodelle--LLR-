---
title: "LLR Notebook"
output: html_notebook
---

#LLR Aufgaben Serie 1

```{r}
### Librarys installieren
#install.packages("tidyverse")
#install.packages("PerformanceAnalytics")
#install.packages("ggfortify")
#install.packages("fastDummies")
#install.packages("dplyr")

library(tidyverse) # core package includes following packages: tidyr, dplyr, ggplot2, readr, purrr, tibble, stringr, forcats
library(plotly)
library("PerformanceAnalytics") #for correlation
library(broom) # for model quantification
library(ggfortify) # for visualizing model fits
library(fastDummies)
library(dplyr)
library(ggplot2)
```

## Aufgabe 2
```{r}
# Vektoren definieren
x <- c(-2,-1,3,4,6)
y <- c(0,0.5,2,2,5)
```

###Model machen
```{r}
# die lineare Regression mit dem Befehl lm machen
model <- lm(y~x)
summary(model)
```
###Regressionsgerade
```{r}
# die Regressionsgerade plotten
plot(x,y, col = "blue", main = "Plot zu Aufgabe 2", abline(lm(y~x)))
```
###Residuen
```{r}
hist(rstandard(model))
hist(residuals(model))
```

```{r}
#Residuen anschauen
res <- resid(model)

plot(fitted(model), res)

#Eine horizontale Linie bei 0 hinzufügen
abline(0,0)
```
## Aufgabe 3
```{r}
# Datenset einlesen
employees <- read.csv2("employees.csv", sep = ",")
```

```{r}
# Unbrauchbare Daten herausfiltern. Also diejenigen mit Absenz = 0 sollen raus
employees_clean <- subset(employees, AbsentHours > 0)
```

```{r}
#Die unnötigen Zeilen rausnehmen, damit der Laptop nicht mit allen Daten rechnen muss
employees_clean <- subset(employees_clean,  select=c(EmployeeNumber, Age, LengthService, AbsentHours))
```

```{r}
class(employees_clean$AbsentHours)
```
###Age Plots machen
```{r}
#Plot mal anschauen
plot(AbsentHours ~ Age, data = employees_clean)
```

```{r}
#Plot mit Regressionsgerade machen
ggplot(employees_clean, aes(`Age`,`AbsentHours`))+
  geom_jitter()+
  geom_smooth(method = "lm", se = FALSE, color = "yellow")

#funktioniert nicht so, wie ich es mir vorgestellt habe...
```

```{r}
#FUNKTIONIERT NICHT: Schauen, ob die Absenzen mit dem Alter zusammenhängen
#linear_alter <- lm(AbsentHours~Age, data = employees_clean)
#summary(linear_alter)
```

###Age: Regressionsgerade
```{r}
#Da es im oberen Plot nicht so funktioniert, wie ich das möchte, muss ich die Daten von Age und AbsentHours bearbeiten. Sie sind momentan als Character drin. Ich könnte es mal mit as.factor oder as.numeric versuchen, vielleicht klappt es dann. Ich beginne mit as.numeric, weil das im Beispiel von Lucia im Tukeyanscombe auch so drin ist. 

ausprobieren <- employees_clean
ausprobieren$Age <- as.numeric(ausprobieren$Age)
ausprobieren$AbsentHours <- as.numeric(ausprobieren$AbsentHours)
ausprobieren$LengthService <- as.numeric(ausprobieren$LengthService)


ggplot(ausprobieren, aes(`Age`,`AbsentHours`))+
  geom_jitter()+
  geom_smooth(method = "lm", se = FALSE, color = "red")

# AS.NUMERIC, es ist AS.NUMERIC!!!!
```

```{r}
age_anschauen <- ggplot(ausprobieren, aes(`Age`,`AbsentHours`))+
  geom_jitter()+
  geom_smooth(method = "lm", se = FALSE, color = "red")
```

```{r}
summary(age_anschauen)
```
### Age: Modell machen
```{r}
model_employees <- lm(Age~AbsentHours, data = ausprobieren)
summary(model_employees)
```
### Age: Residuen
```{r}
#Als nächstes muss ich die Residuen anschauen 
hist(residuals(model_employees))
```

```{r}
#Residuen anschauen
res <- resid(model_employees)

plot(fitted(model_employees), res)

#Eine horizontale Linie bei 0 hinzufügen
abline(0,0)
```

```{r}
#Residuen again
res <- resid(ausprobieren)
ggplot(ausprobieren, aes(`Age`,res))+
  geom_jitter()
```

### LengthService: Modell machen
```{r}
model_length <- lm(LengthService~AbsentHours, data = ausprobieren)
summary(model_length)
```
###LengthService: Plot machen
```{r}
#Plot machen
plot(AbsentHours ~ LengthService, data = ausprobieren)
```
###LengthService: Regressionsgerade
```{r}
#Plot machen mit Regressionsgerade
ggplot(ausprobieren, aes(`LengthService`,`AbsentHours`))+
  geom_jitter()+
  geom_smooth(method = "lm", se = FALSE, color = "red")
```

###LengthService: Residuen
```{r}
#Als nächstes muss ich die Residuen anschauen 
hist(residuals(model_length))
```

```{r}
res <- resid(model_length)

plot(fitted(model_length), res)

#Eine horizontale Linie bei 0 hinzufügen
abline(0,0)
```

### a) Alle Daten, die bei 0 liegen, rausnehmen mit >0
### b) Hier den R Square anschauen. Umso näher bei 1 er ist, desto mehr hängen die Absenzen mit dem Alter oder der LenghtService ab. R Square ist der Abstand der Residuen im Quadrat. Also umso näher er bei 1 ist, desto näher sind die Residuen bei der Regressionsgeraden und desto mehr hängen sie folglich von einander ab. Der R Square von Alter und Absenzen liegt bei 0.64 und der bei der Arbeitsdauer und den Absenzen liegt bei 0.0005. Das heisst also, dass die Anzahl Absenzen eher vom Alter abhängt. 
### c) ?
### d) Das sind die Bedingungen für die Resuidenanalyse: 
      1) Die Residuen haben den Erwartungswert 0, d.h. es sollte keine
        systematischen Fehler geben im Modell.
      2) Die Fehler sollten unabhängig voneinander sein.
      3) Die Fehler sollten normalverteilt sein, was man nicht im TukeyAnscombe-Diagramm prüft, sondern in einem                 Histogramm.
### e) Siehe b)
### f) Mein Rat: Wenn die Firma weniger Absenzen möchte, sollte sie jüngere Mitarbeiterinnen und Mitarbeiter einstellen.

## Aufgabe 4
Lösung: Odds ratio machen
## Aufgabe 5
```{r}
# Datenset einlesen und filtern
umfragedaten <- read.csv2("Umfragedaten.csv", sep = ",")
data_clean <- subset(umfragedaten,  select=c(RAUCH, NETTO))
data_clean <- na.omit(data_clean)
```

```{r}
# Ja und Nein bei der Spalte RAUCH zu 0 und 1 machen, 0 = Nein, 1 = Ja
data_clean$RAUCH[data_clean$RAUCH == "JA"] <- "1"
data_clean$RAUCH[data_clean$RAUCH == "NEIN"] <- "0"
```

```{r}
#Nicht vergessen, 0 und 1 müssen numerisch sein, hier sind sie durch das "" zu Buchstaben oder so geworden
data_clean$RAUCH <-as.numeric(data_clean$RAUCH)
#data_clean$NETTO <-as.numeric(data_clean$NETTO)
```

```{r}
#den Code richtig zusammenstellen
data_glm <- glm(
  RAUCH ~ NETTO, 
  data = data_clean, 
  family = binomial)
```

```{r}
summary(data_glm)
```

```{r}
#Mal eine Grafik plotten
ggplot(data_clean, aes(NETTO, RAUCH))+
  geom_point()+
  geom_smooth(method = "glm", se = FALSE, method.args = list(family = binomial))
```

```{r}
#die Grafik ist noch nicht ganz das, was ich möchte. Es muss ja ein S sein. Daher sollte ich das mal mit dem Logarithmus versuchen
netto_log <- log(data_clean$NETTO, base = exp(1))
#rauch_log <- log(data_clean$RAUCH, base = exp(1))
ggplot(data_clean, aes(netto_log, RAUCH))+
  geom_point()+
  geom_smooth(method = "glm", se = FALSE, method.args = list(family = binomial))
```

```{r}
# Jetzt noch rauszoomen, dann sollte eine schöne S-Kurve zu sehen sein
netto_log <- log(data_clean$NETTO, base = exp(1))
ggplot(data_clean, aes(netto_log, RAUCH))+
  geom_point()+
  geom_smooth(method = "glm", se = FALSE, method.args = list(family = binomial))+
  xlim(-10, 40)+
  ylim(-0.2, 1.2)
```
###Verbesserung von Lucia:
```{r}
##Man kann z.B. so Punkte zwischen -10 und 40 für die x-Achse definieren:
#mehr Datenpunkte definieren:
netto_log <- data.frame(NETTO=-10:40)

#kuerzere Variablennamen, damit ich weniger tippen muss
xx <- log(data_clean$NETTO, base = exp(1))
yy <- data_clean$RAUCH

#Modell, welches direkt mit log berechnet wird
data_glm2 <- glm(yy ~ xx, family = binomial)
summary(data_glm2)
```


```{r}
#Danach kann man aus dem berechneten Modell die Steigung und das Intercept nehmen und direkt die S-Kurve mit den vorgegebenen x-Werten berechnen.
steigung = data_glm2[["coefficients"]][["xx"]]
intercept = data_glm2[["coefficients"]][["(Intercept)"]]
pi <- exp(intercept+steigung*netto_log$NETTO) / (1+exp(intercept+steigung*netto_log$NETTO))

#plot der Originaldaten und der S-Kurve
plot(xx,data_clean$RAUCH, xlim=c(-10, 40))
lines(netto_log$NETTO,pi)

```

```{r}
### Jetzt kommt das mit der prediction
linear_model <- glm(RAUCH~NETTO, data = data_clean, family = "binomial")
explanatory_data <- tibble("data_clean$RAUCH" = seq(-1,6,0.25))
prediction_data <- explanatory_data %>%
  mutate(RAUCH = predict(linear_model, explanatory_data, type = "response"))
```

```{r}
#Versuche jetzt herauszufinden, wie hoch die Wahrscheinlichkeit ist, dass jemand, der 2000.- verdient, Raucher ist. 
relation <- lm(RAUCH~NETTO, data = data_clean)

a <- data.frame(NETTO=2000)
result <- predict(relation, a)
print(result)

#Das Resultat 0.2955645 also 29.55 Prozent stimmt. Python berechnet das anders als R und Lucia weiss nicht genau, welche Werte da ausgelassen worden sind oder was genau der Grund für die andere Lösung ist. Aber immerhin: Es stimmt. Yay!
```

## Aufgabe 6
```{r}
#Daten einlesen
voice <- read.csv2("voice.csv", sep = ",")
```
### a) Bestimmen Sie, welche der drei obigen Variablen am besten zur Klassifikation weiblich/männlich geeignet ist:

```{r}
#meanfreq: mean frequency (in kHz)
#• median: median frequency (in kHz)
#• meanfun: average fundamental frequency measured across acoustic signa
#Mein Lösungsansatz: Zunächst männlich und weiblich zu 1 und 0 ändern, dann eine logistische Regression machen und anhand von R-Square herausfinden, was am meisten zusammenhängt. 1 = Mann und 0 = Frau

#Zunächst werde ich die unnötigen Daten herausfiltern, sodass ich nur noch Geschlecht, mean frequency, median frequency und average fundamental frequency habe. 

voice_clean <- subset(voice,  select=c(meanfreq, label, median, meanfun))
```

```{r}
#Geschlecht in Zahlen ändern, männlich = 1 und weiblich = 0
voice_clean$label[voice_clean$label == "male"] <- "1"
voice_clean$label[voice_clean$label == "female"] <- "0"
```

```{r}
#Kurz schauen, ob es nummerisch ist
class(voice_clean$label)
```

```{r}
#Nicht vergessen, 0 und 1 müssen numerisch sein, hier sind sie durch das "" zu Buchstaben oder so geworden
voice_clean$label <-as.numeric(voice_clean$label)
voice_clean$meanfreq <- as.numeric(voice_clean$meanfreq)
```

```{r}
#Kurz schauen, ob es jetzt nummerisch ist
class(voice_clean$label)
```
```{r}
#Plot mit meanfreq anschauen
plot(label ~ meanfreq, data = voice_clean)
#Man sieht, dass Männer generell eine tiefere meanfreq (mittlere Frequenz der Stimme haben). Auch sieht man einen grossen Überlapp, sodass wir uns schon denken koennen, dass ein logistisches Modell Mühe haben koennte.

```
```{r}
#die x-Achse sortieren, damit nicht die Regressionsgerade nicht hin und her springt
order_voice <- voice_clean[order(voice_clean$meanfreq),]

freq <- log(order_voice$meanfreq, base = exp(1))
label <- order_voice$label


#Modell, welches direkt mit log berechnet wird
meanfreq_glm <- glm(label ~ freq, family = binomial)
summary(meanfreq_glm)

#Danach kann man aus dem berechneten Modell die Steigung und das Intercept nehmen und direkt die S-Kurve mit den vorgegebenen x-Werten berechnen.
steigung_freq = meanfreq_glm[["coefficients"]][["freq"]]
intercept_freq = meanfreq_glm[["coefficients"]][["(Intercept)"]]
freq_pi <- exp(intercept_freq+steigung_freq*freq) / (1+exp(intercept_freq+steigung_freq*freq))

#plot der Originaldaten und der S-Kurve
plot(freq,order_voice$label)
lines(freq, freq_pi)
```

```{r}
#Jetzt mit ggplot:

#die x-Achse sortieren, damit nicht die Regressionsgerade nicht hin und her springt
order_voice <- voice_clean[order(voice_clean$meanfreq),]

freq <- log(order_voice$meanfreq, base = exp(1))
label <- order_voice$label


#Modell, welches direkt mit log berechnet wird
meanfreq_glm <- glm(label ~ freq, family = binomial)
summary(meanfreq_glm)

#Danach kann man aus dem berechneten Modell die Steigung und das Intercept nehmen und direkt die S-Kurve mit den vorgegebenen x-Werten berechnen.
steigung_freq = meanfreq_glm[["coefficients"]][["freq"]]
intercept_freq = meanfreq_glm[["coefficients"]][["(Intercept)"]]
freq_pi <- exp(intercept_freq+steigung_freq*freq) / (1+exp(intercept_freq+steigung_freq*freq))

#plot der Originaldaten und der S-Kurve
ggplot(meanfreq_glm, aes(freq, label))+
  geom_point()+
  geom_smooth(method = "glm", se = FALSE, method.args = list(family = binomial))
```

```{r}
##Man kann z.B. so Punkte zwischen -10 und 40 für die x-Achse definieren:
#mehr Datenpunkte definieren:
freq_log <- data.frame(meanfreq=-10:10)

#kuerzere Variablennamen, damit ich weniger tippen muss
x_freq <- log(order_voice$meanfreq, base = exp(1))
y_label <- order_voice$label

#Modell, welches direkt mit log berechnet wird
meanfreq_glm <- glm(y_label ~ x_freq, family = binomial)
summary(meanfreq_glm)

#Danach kann man aus dem berechneten Modell die Steigung und das Intercept nehmen und direkt die S-Kurve mit den vorgegebenen x-Werten berechnen.
steigung_freq = meanfreq_glm[["coefficients"]][["x_freq"]]
intercept_freq = meanfreq_glm[["coefficients"]][["(Intercept)"]]
freq_pi <- exp(intercept_freq+steigung_freq*x_freq) / (1+exp(intercept_freq+steigung_freq*x_freq))

#plot der Originaldaten und der S-Kurve
ggplot(meanfreq_glm, aes(x_freq, y_label))+
  geom_point()+
  geom_smooth(method = "glm", se = FALSE, method.args = list(family = binomial), xlim=c(-10, 10))
```

```{r}
#Und jetzt das gleiche auch noch mit den anderen zwei Variablen machen
```
## Aufgabe von Anna: 
Basierend auf folgendem Datensatz und zusammenfassender Statistik:
x 6 9 12 15 18 25
y 20 18 10 8 9 4
Mittelwert x = 14:17, Standardabweichung x = 6:79
Mittelwert y = 11:50, Standardabweichung y = 6:19
Korrelation r = −0:920
1 Was ist die Steigung der geschätzten Regressionsgleichung?
2 Was ist der y-Achsenabschnitt der geschätzten Regressionsgleichung?
3 Was ist der vorhergesagte Wert von y, wenn x 25 ist?
4 Was ist sein Residuum?
```{r}
#1. Was ist die Steigung der geschätzten Regressionsgleichung?
#2. Was ist der y-Achsenabschnitt der geschätzten Regressionsgleichung?
xA <- c(6,9,12,15,18,25)
yA <- c(20,18,10,8,9,4)

modelA <- lm(yA ~ xA)
summary(modelA)

#1. die Steigung ist -0.8383
#2. der y-Achsenabschnitt ist 23.3755
```
```{r}
#Was ist der vorhergesagte Wert von y, wenn x 25 ist?
relationA <- lm(yA~xA)

aA <- data.frame(xA=25)
result <- predict(relationA, aA)
print(result)

#das Resultat ist 2.418773
```

```{r}
#4 Was ist sein Residuum?
res <- resid(modelA, xA=25)

print(res)
#die erste Lösung stimmt, 1.6541516
```
#Aufgaben aus dem Marcel Steiner Skript

## Problem 7.5.1 (Venice Sea Level, cf. [8], Example 5.1). The annual maximum sea levels
[in cm] in Venice, 1931-1981 have been recorded by P. A. Pirazzoli. The data set venice.dat
contains the annual maximum tides at Venice for the 51 years.
a. Represent the data in a scatter diagram sea level versus year and describe the functional
context in words.
b. Fit a straight line to the data points. Give the estimated parameter values.
c. Add the model in the scatter diagram. Comment on the solution.
d. Does the data support the hypothesis that Venice sinks?
```{r}
#Daten einlesen
venice <- read.csv2("venice.csv", header=TRUE, sep = ",")
```
###a) Represent the data in a scatter diagram sea level versus year and describe the functional
```{r}
plot(SeaLevel ~ Year, data = venice)
#Es könnte ein leichter Zusammenhang zwischen den Jahren und dem Meeresspiegel bestehen. Die lineare Funktion steigt leicht, also könnte es sein, dass Venedig leicht untergeht. 
```
###b) Fit a straight line to the data points. Give the estimated parameter values.
```{r}
ggplot(venice, aes(`Year`,`SeaLevel`))+
  geom_jitter()+
  geom_smooth(method = "lm", se = FALSE, color = "red")
```

```{r}
model_venice <- lm(SeaLevel~Year, data = venice)
summary(model_venice)
#die Parameter lauten y=0.5670x -989.3822
```

